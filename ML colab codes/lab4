{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **LAB 4_0**"],"metadata":{"id":"sVdRfd6fb2CV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWEQ2ZhCapvF"},"outputs":[],"source":["# Import Numpy & PyTorch\n","import numpy as np\n","import torch\n","\n","# Input (temp, rainfall, humidity)\n","input = np.array([[73, 67, 43],\n","[91, 88, 64],\n","[87, 134, 58],\n","[102, 43, 37],\n","[69, 96, 70]], dtype='float32')\n","\n","target = np.array([[56],\n","[81],\n","[119],\n","[22],\n","[103]], dtype='float32')\n","\n","# generate model\n","\n","initial_target=np.array([[100],\n","[100],\n","[80],\n","[90],\n","[100]], dtype='float32') # taking random values\n","\n","weight = np.array([[10],\n","[20],\n","[15],\n","[11],\n","[30]], dtype='float32')\n","\n","bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n","\n","# Generate predictions\n","\n","prediction = (initial_target*weight) + bias\n","\n","  # print(prediction)\n","\n","# MSE loss\n","  # from sklearn.metrics import mean_squared_error\n","  # x=mean_squared_error(target,prediction)\n","  # print(x)\n","\n","# import numpy as np\n","# MSE = np.square(np.subtract(target,prediction)).mean()\n","# print(MSE)"]},{"cell_type":"code","source":["# Compute Gradients\n","import torch\n","from torch.utils.data import TensorDataset,DataLoader\n","\n","\n","inputs = torch.from_numpy(input)\n","targets = torch.from_numpy(target)\n","\n","  # print(inputs)\n","  # print(targets)\n","dataset = TensorDataset(inputs,targets)\n","  # print(dataset[:5])\n","train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","# Adjust weights and biases using gradient descent\n","weights= torch.randn(1,3, requires_grad=True)\n","biass = torch.randn(1, requires_grad=True)\n","\n","print(weights)\n","print(biass)\n","\n","def model(X):\n","  return X @ weights.t() + biass  # '@' - for matrix multiplication\n","\n","for x,y in train_loader:\n","    preds = model(x)\n","    print(\"Prediction is :\\n\",preds)\n","    print(\"\\nActual targets is :\\n\",y)\n","    break\n","\n","# Calculate the loss\n","def mse_loss(predictions, targets):\n","  difference = predictions - targets\n","  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n","\n","for x,y in train_loader:\n","  preds=model(x)\n","  print(\"Prediction is :\\n\", preds)\n","  print(\"\\nActual targets is :\\n\",y)\n","  print(\"\\nLoss is: \",mse_loss(preds,y))\n","  break\n","\n","epochs = 1000\n","for i in range(epochs):\n","    # Iterate through training dataloader\n","    for x,y in train_loader:\n","        # Generate Prediction\n","        preds = model(x)\n","\n","        # Get the loss and perform backpropagation\n","        loss = mse_loss(preds, y)\n","        loss.backward()\n","\n","        # Let's update the weights\n","        with torch.no_grad():\n","            weights -= weights.grad *1e-5\n","            biass -= biass.grad * 1e-5\n","            # Set the gradients to zero\n","            weights.grad.zero_()\n","            biass.grad.zero_()\n","    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n","\n","for x,y in train_loader:\n","  preds= model(x)\n","  print(\"\\nFinal Prediction is :\\n\",preds)\n","  print(\"\\nActual targets are :\\n\",y)\n","  break"],"metadata":{"id":"Z5JRXRcig76Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676867671008,"user_tz":-330,"elapsed":2048,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"d088b492-b736-482d-f7b8-74a9e259f8ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.9296,  1.6733, -0.5636]], requires_grad=True)\n","tensor([0.4952], requires_grad=True)\n","Prediction is :\n"," tensor([[ 20.5118],\n","        [ 57.5381],\n","        [ 27.0827],\n","        [111.1546]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[ 56.],\n","        [103.],\n","        [ 81.],\n","        [119.]])\n","Prediction is :\n"," tensor([[111.1546],\n","        [ 27.0827],\n","        [ 20.5118],\n","        [-43.2234]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[119.],\n","        [ 81.],\n","        [ 56.],\n","        [ 22.]])\n","\n","Loss is:  tensor(2120.5337, grad_fn=<DivBackward0>)\n","\n","Final Prediction is :\n"," tensor([[101.5483],\n","        [ 81.9818],\n","        [119.0094],\n","        [ 21.2213]], grad_fn=<AddBackward0>)\n","\n","Actual targets are :\n"," tensor([[103.],\n","        [ 81.],\n","        [119.],\n","        [ 22.]])\n"]}]},{"cell_type":"code","source":["print(weights)\n","print(biass)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hm0zkWVbo5yP","executionInfo":{"status":"ok","timestamp":1676867671009,"user_tz":-330,"elapsed":4,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"61885368-ebd3-4f64-c402-70c38b55e2a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.3977,  0.8566,  0.6608]], requires_grad=True)\n","tensor([0.5067], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# 5. Use the model to predict crop yield for apples if temperature is 70, Rain is 34 and Humidity is 45.\n","from sklearn.linear_model import LinearRegression\n","\n","model = LinearRegression()\n","\n","model.fit(inputs, targets)\n","\n","# for x,y in dataset:\n","#   print(x,y)\n","\n","test_input = np.array([[70, 34, 45]])\n","\n","y_pred = model.predict(test_input)\n","print(\"Prediction: \", y_pred)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9qx3OZgjLiL","executionInfo":{"status":"ok","timestamp":1676867673341,"user_tz":-330,"elapsed":2335,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"b3631f81-784a-4782-e095-5b7087537e92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction:  [[31.47395247]]\n"]}]},{"cell_type":"code","source":["# 1. Estimate the value of model parameters(weights and bias) and MSE Loss after training for 1000 epochs.\n","import numpy as np\n","MSE = mse_loss(preds,y)\n","print(\"MSE: \",MSE)\n","\n","print(\"Weights: \",weights)\n","print(\"Bias: \",biass)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mn4tSm33cwBj","executionInfo":{"status":"ok","timestamp":1676867673342,"user_tz":-330,"elapsed":3,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"6fcc5198-30f8-4661-d59e-800195d23289"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  tensor(0.9195, grad_fn=<DivBackward0>)\n","Weights:  tensor([[-0.3977,  0.8566,  0.6608]], requires_grad=True)\n","Bias:  tensor([0.5067], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# 2. Take the learning rate value as 0.1 and train the model. Write in brief the impact of this learning rate on the model.\n","# Compute Gradients\n","# Import Numpy & PyTorch\n","import numpy as np\n","import torch\n","\n","# Input (temp, rainfall, humidity)\n","input = np.array([[73, 67, 43],\n","[91, 88, 64],\n","[87, 134, 58],\n","[102, 43, 37],\n","[69, 96, 70]], dtype='float32')\n","\n","target = np.array([[56],\n","[81],\n","[119],\n","[22],\n","[103]], dtype='float32')\n","\n","# generate model\n","\n","initial_target=np.array([[100],\n","[100],\n","[80],\n","[90],\n","[100]], dtype='float32') # taking random values\n","\n","weight = np.array([[10],\n","[20],\n","[15],\n","[11],\n","[30]], dtype='float32')\n","\n","bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n","\n","# Generate predictions\n","\n","prediction = (initial_target*weight) + bias\n","\n","  # print(prediction)\n","\n","# MSE loss\n","  # from sklearn.metrics import mean_squared_error\n","  # x=mean_squared_error(target,prediction)\n","  # print(x)\n","\n","# import numpy as np\n","# MSE = np.square(np.subtract(target,prediction)).mean()\n","# print(MSE)\n","\n","import torch\n","from torch.utils.data import TensorDataset,DataLoader\n","\n","\n","inputs = torch.from_numpy(input)\n","targets = torch.from_numpy(target)\n","\n","  # print(inputs)\n","  # print(targets)\n","dataset = TensorDataset(inputs,targets)\n","  # print(dataset[:5])\n","train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","# Adjust weights and biases using gradient descent\n","weights= torch.randn(1,3, requires_grad=True)\n","biass = torch.randn(1, requires_grad=True)\n","\n","print(weights)\n","print(biass)\n","\n","def model(X):\n","  return X @ weights.t() + biass  # '@' - for matrix multiplication\n","\n","for x,y in train_loader:\n","    preds = model(x)\n","    print(\"Prediction is :\\n\",preds)\n","    print(\"\\nActual targets is :\\n\",y)\n","    break\n","\n","# Calculate the loss\n","def mse_loss(predictions, targets):\n","  difference = predictions - targets\n","  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n","\n","for x,y in train_loader:\n","  preds=model(x)\n","  print(\"Prediction is :\\n\", preds)\n","  print(\"\\nActual targets is :\\n\",y)\n","  print(\"\\nLoss is: \",mse_loss(preds,y))\n","  break\n","\n","epochs = 1000\n","for i in range(epochs):\n","    # Iterate through training dataloader\n","    for x,y in train_loader:\n","        # Generate Prediction\n","        preds = model(x)\n","\n","        # Get the loss and perform backpropagation\n","        loss = mse_loss(preds, y)\n","        loss.backward()\n","\n","        # Let's update the weights\n","        with torch.no_grad():\n","            weights -= weights.grad *0.1\n","            biass -= biass.grad * 0.1\n","            # Set the gradients to zero\n","            weights.grad.zero_()\n","            biass.grad.zero_()\n","    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n","\n","for x,y in train_loader:\n","  preds= model(x)\n","  print(\"\\nFinal Prediction is :\\n\",preds)\n","  print(\"\\nActual targets are :\\n\",y)\n","  break"],"metadata":{"id":"6CcWleI9ff0g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676867677233,"user_tz":-330,"elapsed":3894,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"dd35522d-f847-4e61-c5fd-a8d8d59b3105"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5443, -0.6599, -0.8511]], requires_grad=True)\n","tensor([-0.2674], requires_grad=True)\n","Prediction is :\n"," tensor([[ -3.6984],\n","        [-16.6343],\n","        [ 97.3894],\n","        [ 27.7269]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[119.],\n","        [103.],\n","        [ 22.],\n","        [ 81.]])\n","Prediction is :\n"," tensor([[ -3.6984],\n","        [ 97.3894],\n","        [-16.6343],\n","        [ 27.7269]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[119.],\n","        [ 22.],\n","        [103.],\n","        [ 81.]])\n","\n","Loss is:  tensor(9472.2080, grad_fn=<DivBackward0>)\n","\n","Final Prediction is :\n"," tensor([[nan],\n","        [nan],\n","        [nan],\n","        [nan]], grad_fn=<AddBackward0>)\n","\n","Actual targets are :\n"," tensor([[ 81.],\n","        [119.],\n","        [103.],\n","        [ 22.]])\n"]}]},{"cell_type":"code","source":["import numpy as np\n","MSE = mse_loss(preds,y)\n","print(\"MSE: \",MSE)\n","\n","print(\"Weights: \",weights)\n","print(\"Bias: \",biass)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spzhv3qrf_bw","executionInfo":{"status":"ok","timestamp":1676867677234,"user_tz":-330,"elapsed":13,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"534057d5-b130-4345-9cb5-f276607ec3ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  tensor(nan, grad_fn=<DivBackward0>)\n","Weights:  tensor([[nan, nan, nan]], requires_grad=True)\n","Bias:  tensor([nan], requires_grad=True)\n"]}]},{"cell_type":"code","source":["# 3. Take the learning rate value as 0.0000001 and train the model. Write in brief the impact of this learning rate on the model.\n","# Compute Gradients\n","# Import Numpy & PyTorch\n","import numpy as np\n","import torch\n","\n","# Input (temp, rainfall, humidity)\n","input = np.array([[73, 67, 43],\n","[91, 88, 64],\n","[87, 134, 58],\n","[102, 43, 37],\n","[69, 96, 70]], dtype='float32')\n","\n","target = np.array([[56],\n","[81],\n","[119],\n","[22],\n","[103]], dtype='float32')\n","\n","# generate model\n","\n","initial_target=np.array([[100],\n","[100],\n","[80],\n","[90],\n","[100]], dtype='float32') # taking random values\n","\n","weight = np.array([[10],\n","[20],\n","[15],\n","[11],\n","[30]], dtype='float32')\n","\n","bias = np.array([[7],[7],[7],[7],[7]],dtype='float32')\n","\n","# Generate predictions\n","\n","prediction = (initial_target*weight) + bias\n","loss_arr=[];\n","  # print(prediction)\n","\n","# MSE loss\n","  # from sklearn.metrics import mean_squared_error\n","  # x=mean_squared_error(target,prediction)\n","  # print(x)\n","\n","# import numpy as np\n","# MSE = np.square(np.subtract(target,prediction)).mean()\n","# print(MSE)\n","\n","import torch\n","from torch.utils.data import TensorDataset,DataLoader\n","\n","\n","inputs = torch.from_numpy(input)\n","targets = torch.from_numpy(target)\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(inputs, targets, random_state=97)\n","\n","  # print(inputs)\n","  # print(targets)\n","dataset = TensorDataset(inputs,targets)\n","  # print(dataset[:5])\n","train_loader = DataLoader(dataset, batch_size=4, shuffle=True)\n","\n","# Adjust weights and biases using gradient descent\n","weights= torch.randn(1,3, requires_grad=True)\n","biass = torch.randn(1, requires_grad=True)\n","\n","print(weights)\n","print(biass)\n","\n","def model(X):\n","  return X @ weights.t() + biass  # '@' - for matrix multiplication\n","\n","for x,y in train_loader:\n","    preds = model(x)\n","    print(\"Prediction is :\\n\",preds)\n","    print(\"\\nActual targets is :\\n\",y)\n","    break\n","\n","# Calculate the loss\n","def mse_loss(predictions, targets):\n","  difference = predictions - targets\n","  return torch.sum(difference * difference)/ difference.numel() # numel() method returns the number of elements in the tensor.\n","\n","for x,y in train_loader:\n","  preds=model(x)\n","  print(\"Prediction is :\\n\", preds)\n","  print(\"\\nActual targets is :\\n\",y)\n","  print(\"\\nLoss is: \",mse_loss(preds,y))\n","  break\n","\n","\n","\n","epochs = 1000\n","for i in range(epochs):\n","    # Iterate through training dataloader\n","    for x,y in train_loader:\n","        # Generate Prediction\n","        preds = model(x)\n","\n","        # Get the loss and perform backpropagation\n","        \n","        loss = mse_loss(preds, y)\n","        loss_arr+=loss\n","        # np.append(loss_arr,loss,axis=0)\n","        loss.backward()\n","\n","        # Let's update the weights\n","        with torch.no_grad():\n","            weights -= weights.grad *1e-7\n","            biass -= biass.grad * 1e-7\n","            # Set the gradients to zero\n","            weights.grad.zero_()\n","            biass.grad.zero_()\n","    #print(f\"Epoch {i}/{epochs}: Loss: {loss}\")\n","\n","for x,y in train_loader:\n","  preds= model(x)\n","  print(\"\\nFinal Prediction is :\\n\",preds)\n","  print(\"\\nActual targets are :\\n\",y)\n","  break"],"metadata":{"id":"_SAadQNoglMJ","colab":{"base_uri":"https://localhost:8080/","height":901},"executionInfo":{"status":"error","timestamp":1676869170789,"user_tz":-330,"elapsed":440,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"34855892-6817-4e1d-c4ee-d3810871687d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.0878,  0.1406,  0.9236]], requires_grad=True)\n","tensor([-0.8850], requires_grad=True)\n","Prediction is :\n"," tensor([[-71.6210],\n","        [  2.2105],\n","        [-23.1095],\n","        [-31.1571]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[ 22.],\n","        [103.],\n","        [119.],\n","        [ 56.]])\n","Prediction is :\n"," tensor([[-71.6210],\n","        [-23.1095],\n","        [-31.1571],\n","        [  2.2105]], grad_fn=<AddBackward0>)\n","\n","Actual targets is :\n"," tensor([[ 22.],\n","        [119.],\n","        [ 56.],\n","        [103.]])\n","\n","Loss is:  tensor(11678.7197, grad_fn=<DivBackward0>)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-7ba0637b2662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_arr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4815\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4816\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."]}]},{"cell_type":"code","source":["print(loss_arr)"],"metadata":{"id":"m86s-X2qJ4Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","MSE = mse_loss(preds,y)\n","print(\"MSE: \",MSE)\n","\n","print(\"Weights: \",weights)\n","print(\"Bias: \",biass)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ndv5ujlAg01Q","executionInfo":{"status":"ok","timestamp":1676868016523,"user_tz":-330,"elapsed":457,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"9de53406-e8ac-4da3-a7e4-e81fe5414187"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  tensor(16.6000, grad_fn=<DivBackward0>)\n","Weights:  tensor([[-0.3495,  0.9894,  0.3542]], requires_grad=True)\n","Bias:  tensor([1.1458], requires_grad=True)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","model = LinearRegression()\n","\n","history = model.fit(X_train, y_train)\n","print(history.)\n","# loss_train = history['train_loss']\n","# epochs = range(1,1000)\n","# plt.plot(epochs, loss_train, 'g', label='Training loss')\n","# plt.title('Training loss')\n","# plt.xlabel('Epochs')\n","# plt.ylabel('Loss')\n","# plt.legend()\n","# plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhXWMQ2CF-5j","executionInfo":{"status":"ok","timestamp":1676868261319,"user_tz":-330,"elapsed":427,"user":{"displayName":"CE097_MANUSHI_ PATEL","userId":"05147334420162993700"}},"outputId":"8c27c643-b414-4f6d-e1be-2ae6ca95427b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LinearRegression()\n"]}]},{"cell_type":"markdown","source":["# **LAB 4_1**"],"metadata":{"id":"YrayHrngshS4"}},{"cell_type":"code","source":["# Import Numpy & PyTorch\n","import numpy as np\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","\n","input = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37],[69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69,96, 70],\n","                   [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96,70]], dtype='float32')\n","# Targets (apples, oranges)\n","target = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],[56, 70], [81, 101], [119, 133], [22, 37], [103, 119],\n","[56, 70], [81, 101], [119, 133], [22, 37], [103, 119]],dtype='float32')\n","\n","inputs = torch.from_numpy(input)\n","targets = torch.from_numpy(target)\n","\n","# Define dataset\n","train_ds = TensorDataset(inputs,targets)\n","\n","# Define data loader\n","batch_size = 5\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n","next(iter(train_dl))\n","\n","# Define model\n","model = nn.Linear(3,2)\n","print(model.weight)\n","print(model.bias)"],"metadata":{"id":"JcpDWOl7skxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define optimizer\n","opt = torch.optim.SGD(model.parameters(), lr=1e-5)"],"metadata":{"id":"PTwL0A3U4cuG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define loss function\n","import torch.nn.functional as F\n","\n","loss_fn = F.mse_loss\n","loss = loss_fn(model(inputs), targets)\n","print(loss)"],"metadata":{"id":"QsbTLx4K4gyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a utility function to train the model\n","def fit(num_epochs, model, loss_fn, opt):\n","    for epoch in range(num_epochs):\n","        for xb,yb in train_dl:\n","            # Generate predictions\n","            pred = model(xb)\n","            loss = loss_fn(pred, yb)\n","            # Perform gradient descent\n","            loss.backward()\n","            opt.step()\n","            opt.zero_grad()\n","    print('Training loss: ', loss_fn(model(inputs), targets))\n","\n","# Train the model for 100 epochs\n","fit(100, model, loss_fn, opt)"],"metadata":{"id":"ufCoH78Z4uBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate predictions\n","preds = model(inputs)\n","preds"],"metadata":{"id":"eb4L_8Nk6BKW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare with targets\n","targets\n","\n","print(inputs)\n","print(targets)"],"metadata":{"id":"B88_HwA163Tc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fit(100, model, loss_fn, opt)"],"metadata":{"id":"oZg6TlWJ8B3P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Exercise 1:**\n","Try Linear Regression just using numpy (Without Tensorflow/Pytorch or other torch library). You can optionally use sklearn (if you want)."],"metadata":{"id":"NjbTFsQ3Dz4l"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LinearRegression, SGDRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import make_pipeline"],"metadata":{"id":"fTInClJREFLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LinearRegression():\n","    def __init__(self):\n","        self.b0 = 0\n","        self.b1 = 0\n","        \n","    def fit(self, X, y):\n","        mean_x = np.mean(X)\n","        mean_y = np.mean(y)\n","        \n","        SSxy = np.sum(np.multiply(X, y)) - len(x) * mean_x * mean_y\n","        SSxx = np.sum(np.multiply(X, x)) - len(x) * mean_x * mean_x\n","        \n","        self.b1 = SSxy / SSxx\n","        self.b0 = mean_y - self.b1 * mean_x\n","    \n","    def predict(self, input_data):\n","        return self.b0 + self.b1 * input_data"],"metadata":{"id":"iexoRKyyIhv-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n","y = np.array([6, 6, 11, 17, 16, 20, 23, 23, 29, 33, 39])\n","\n","model = LinearRegression()\n","model.fit(x, y)"],"metadata":{"id":"rSXwRrWRLdZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = model.predict(x)\n","plt.scatter(x = x, y = y, color='orange')\n","plt.plot(predictions, color='orange')\n","plt.show()"],"metadata":{"id":"95cgByAdMdVb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Exercise 2:**\n","Try Linear regression on same prediction data using Tensorflow."],"metadata":{"id":"geWN8REuOqXW"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","\n","np.random.seed(101)\n","tf.random.set_seed(101)"],"metadata":{"id":"j6Fx-GpUOuDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generating random linear data\n","# There will be 50 data points ranging from 0 to 50\n","\n","# x = np.linspace(0, 50, 50)\n","# y = np.linspace(0, 50, 50)\n","x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n","y = np.array([6, 6, 11, 17, 16, 20, 23, 23, 29, 33, 39])\n"," \n","# Adding noise to the random linear data\n","# x += np.random.uniform(-4, 4, 50)\n","# y += np.random.uniform(-4, 4, 50)\n"," \n","n = len(x) # Number of data points"],"metadata":{"id":"P9eEl9zFSrgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot of Training Data\n","plt.scatter(x, y)\n","plt.xlabel('x')\n","plt.ylabel('y')\n","plt.title(\"Training Data\")\n","plt.show()"],"metadata":{"id":"EWoRs6UTSu8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip uninstally tensorflow-gpu tensorflow tensorflow-base"],"metadata":{"id":"1LiXrcgLTRlX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install tensorflow"],"metadata":{"id":"QWQ0ffIeThsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","\n","X = tf.compat.v1.placeholder(\"float\")\n","Y = tf.compat.v1.placeholder(\"float\")"],"metadata":{"id":"o725DGCMS0cI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["W = tf.Variable(np.random.randn(), name = \"W\")\n","b = tf.Variable(np.random.randn(), name = \"b\")\n","\n","learning_rate = 0.01\n","training_epochs = 1000\n","\n","# Hypothesis\n","y_pred = tf.add(tf.multiply(X, W), b)\n"," \n","# Mean Squared Error Cost Function\n","cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n"," \n","# Gradient Descent Optimizer\n","optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n"," \n","# Global Variables Initializer\n","init = tf.global_variables_initializer()"],"metadata":{"id":"dIhc7-53UoHS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Starting the Tensorflow Session\n","with tf.Session() as sess:\n","     \n","    # Initializing the Variables\n","    sess.run(init)\n","     \n","    # Iterating through all the epochs\n","    for epoch in range(training_epochs):\n","         \n","        # Feeding each data point into the optimizer using Feed Dictionary\n","        for (_x, _y) in zip(x, y):\n","            sess.run(optimizer, feed_dict = {X : _x, Y : _y})\n","         \n","        # Displaying the result after every 50 epochs\n","        if (epoch + 1) % 50 == 0:\n","            # Calculating the cost a every epoch\n","            c = sess.run(cost, feed_dict = {X : x, Y : y})\n","            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b))\n","     \n","    # Storing necessary values to be used outside the Session\n","    training_cost = sess.run(cost, feed_dict ={X: x, Y: y})\n","    weight = sess.run(W)\n","    bias = sess.run(b)"],"metadata":{"id":"nRVafPQ9U3te"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating the predictions\n","predictions = weight * x + bias\n","print(\"Training cost =\", training_cost, \"Weight =\", weight, \"bias =\", bias, '\\n')"],"metadata":{"id":"r0wjwtUyVf-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting the Results\n","plt.plot(x, y, 'ro', label ='Original data')\n","plt.plot(x, predictions, label ='Fitted line')\n","plt.title('Linear Regression Result')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"wzMSsufcVjDP"},"execution_count":null,"outputs":[]}]}